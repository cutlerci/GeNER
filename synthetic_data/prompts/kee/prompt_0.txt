<Task Descriptions>
You are an experienced biologist, capable of easily recognizing named entities ("species names," "dose units," and "exposure vehicles") in a paragraph of the method section of scientific articles describing animal studies. Specifically, your task is to perform named entity recognition and meet the following basic requirements: 1) Provide the output as a Python dictionary with sample IDs as keys, where each sample contains a list of tokens and their corresponding labels. Python dictionary example: 

{
    "sample1": {
        "tokens": ["XXX", "XXX"],
        "labels": ["XXX", "XXX"]
    },
    "sample2": {
        "tokens": ["XXX", "XXX"],
        "labels": ["XXX", "XXX"]
    }
}

2) Include at least one token for each requested entity type for each sample. 3) You can repeat entities within a sentence or across sentences to ensure diversity in the data.

<Entity Definitions>
In statistical analyses, "GroupName" refers to distinct categories or levels within a dataset that are compared to assess differences or effects. These groupings typically represent experimental conditions, treatment regimens, or other factors of interest being investigated. Assigning observations to appropriate group names allows researchers to conduct comparative evaluations and infer relationships or associations between variables. Group names play a crucial role in hypothesis testing, where researchers aim to determine whether observed differences between groups are statistically significant or merely due to chance.

<Task Emphasis>
1) Each sample should include a list of sentence tokens and their corresponding class labels. It is imperative that the exact same number of class labels are used as tokens in the sentence. 2) Ensure that each label corresponds to its corresponding entity type. 3) Ensure the samples are of adequate length. 4) The complete set of generated samples should cover all requested entity types, but individual samples may vary in the number of entity types included.

<Task Examples>
Here are five examples:

{
	"sample0": {
		"tokens": ['From', 'each', 'sham', '-', 'exposed', 'rat', ',', 'blood', 'samples', 'were', 'also', 'collected', 'at', 'the', 'same', 'time', 'as', 'those', 'in', 'RF', '-', 'exposed', 'rats', 'mentioned', 'above', '.'],
		"labels": ['O', 'O', 'GroupName', 'GroupName', 'GroupName', 'GroupName', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'GroupName', 'GroupName', 'GroupName', 'GroupName', 'O', 'O', 'O']
    }, 
	"sample1": {
		"tokens": ['Significance', 'versus', 'vehicle', 'control', ':', '*', 'p', '<', '0', '.', '05', '.'],
		"labels": ['O', 'O', 'GroupName', 'GroupName', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
    }, 
	"sample2": {
		"tokens": ['We', 'selected', 'significant', 'genes', 'using', 'the', 'following', 'criteria', ':', '1', ')', 'gene', 'expression', 'changes', 'that', 'had', 'a', 'z', '-', 'test', 'p', 'value', 'of', '0', '.', '05', 'vs', '.', 'the', 'control', 'comparison', 'group', ';', '2', ')', 'the', 'absolute', 'value', 'of', 'Z', '-', 'ratio', 'was', 'calculated', 'to', 'be', '1', '.', '5', 'vs', '.', 'the', 'control', 'comparison', 'group', ';', '3', ')', 'the', 'False', 'Discovery', 'Rate', 'for', 'the', 'genes', 'was', '0', '.', '30', ';', '4', ')', 'the', 'average', 'Z', '-', 'score', 'over', 'all', 'sample', 'comparisons', 'were', 'not', 'negative', 'and', 'lastly', ';', '5', ')', 'a', 'one', 'way', 'independent', 'ANOVA', 'test', 'on', 'the', 'sample', 'group', 'p', 'value', 'cut', 'off', 'was', '0', '.', '05', '.'],
		"labels": ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'GroupName', 'GroupName', 'GroupName', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'GroupName', 'GroupName', 'GroupName', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
    }, 
	"sample3": {
		"tokens": ['When', 'one', 'facility', 'was', 'used', 'for', 'an', 'MF', '-', 'exposed', 'group', ',', 'the', 'other', 'was', 'used', 'for', 'the', 'sham', '-', 'exposed', 'group', 'without', 'electric', 'current', 'in', 'its', 'exposure', 'coils', '.'],
		"labels": ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'GroupName', 'GroupName', 'GroupName', 'GroupName', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'GroupName', 'GroupName', 'GroupName', 'GroupName', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
    }, 
	"sample4": {
		"tokens": ['To', 'assess', 'significance', 'between', 'DE', '/', 'FA', 'and', 'FA', '/', 'FA', 'or', 'DE', '/', 'DE', ',', 'we', 'performed', 'a', 'repeated', 'measure', 'two', '-', 'way', 'ANOVA', 'across', 'all', '3', 'weeks', 'while', 'excluding', 'these', 'two', 'data', 'points', '.'],
		"labels": ['O', 'O', 'O', 'O', 'GroupName', 'GroupName', 'GroupName', 'O', 'GroupName', 'GroupName', 'GroupName', 'O', 'GroupName', 'GroupName', 'GroupName', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
    }
}

<Prompt>
Generate 5 synthetic data samples to augment a NER dataset comprising the method section of scientific articles describing animal studies. Start your sample number with "sample1". The entity to recognize is GroupName.